import os
import pickle
from typing import Dict, List, Tuple

import numpy as np
import torch


def load_attention_file(path: str) -> Tuple[torch.Tensor, Dict]:
    with open(path, "rb") as f:
        obj = pickle.load(f)
    if isinstance(obj, dict) and "attn" in obj:
        return obj["attn"], obj.get("meta", {})
    # Backward compatibility: raw tensor saved directly
    if torch.is_tensor(obj):
        return obj, {}
    raise ValueError("Unsupported attention file format")


def spatial_entropy(attn_map_2d: torch.Tensor, threshold: float) -> Dict:
    # attn_map_2d: [P, P]
    S = attn_map_2d
    mean_val = torch.mean(S)
    B = torch.relu(S - mean_val*2)
    B_np = B.detach().cpu().to(torch.float32).numpy()
    binary = (B_np > threshold).astype(np.int32)

    from scipy.ndimage import label
    labeled, num = label(binary, structure=np.ones((3, 3)))

    total = float(B.sum().item())
    if total <= 0:
        return {"spatial_entropy": float("inf"), "labeled_array": labeled, "num_components": 0}

    # Probability mass per component
    probs = []
    for i in range(1, num + 1):
        comp_sum = B_np[labeled == i].sum()
        if comp_sum > 0:
            probs.append(comp_sum / total)
    se = -sum(p * np.log(p) for p in probs if p > 0) if probs else 0.0
    return {"spatial_entropy": float(se), "labeled_array": labeled, "num_components": int(num)}


def elbow_chord(values: List[float]) -> float:
    # Returns threshold value (y), not index
    if len(values) <= 2:
        return min(values) if values else 0.0
    vals = np.array(values, dtype=np.float64)
    order = np.argsort(vals)  # ascending
    y = vals[order]
    x = np.arange(len(y), dtype=np.float64)
    start, end = np.array([x[0], y[0]]), np.array([x[-1], y[-1]])
    line = end - start
    line_len = np.linalg.norm(line)
    if line_len == 0:
        return y[0]
    unit = line / line_len
    vecs = np.stack([x, y], axis=1) - start
    proj = (vecs @ unit)[:, None] * unit
    d = np.linalg.norm(vecs - proj, axis=1)
    elbow_i = int(np.argmax(d))
    return float(y[elbow_i])


def analyze_heads(cfg, attn: torch.Tensor, meta: Dict) -> List[Dict]:
    """Analyze heads and return a ranked list.

    attn: [L, H, 1, V]
    meta: includes patch_size (P)
    """
    L, H, _, V = attn.shape
    P = int(meta.get("patch_size", int(np.sqrt(V))))
    manual_cfg = getattr(cfg.logic, "manual_heads", None)
    manual_pairs = []
    manual_lookup = set()
    if manual_cfg:
        for item in manual_cfg:
            try:
                pair = (int(item["layer"]), int(item["head"]))
                manual_pairs.append(pair)
                manual_lookup.add(pair)
            except (KeyError, TypeError, ValueError):
                continue

    # Criterion 1: head sums over image patches
    sums = []
    for l in range(L):
        for h in range(H):
            s = float(attn[l, h, 0].sum().item())
            sums.append(s)

    thr_val = elbow_chord(sums) if cfg.logic.threshold.method == "chord" else min(sums)

    # Analyze Criterion 2 only for heads above thr_val (by value)
    results: List[Dict] = []
    idx = 0
    for l in range(L):
        for h in range(H):
            s = sums[idx]
            idx += 1
            force_include = (l, h) in manual_lookup
            if s < thr_val and not force_include:
                se = float("inf")
                bottom_row_focus = False
                n_comp = 0
            else:
                a2d = attn[l, h, 0].reshape(P, P)
                se_res = spatial_entropy(a2d, cfg.logic.entropy.binarize_threshold)
                bottom_row_focus = bool((a2d.shape[0] > 0) and (a2d[-1, :] > 0.05).any())
                se = float(se_res["spatial_entropy"])    # lower is better
                labeled = se_res["labeled_array"]
                n_comp = int(se_res["num_components"])
            results.append({
                "layer": l,
                "head": h,
                "attn_sum": s,
                "spatial_entropy": se,
                "bottom_row_focus": bottom_row_focus,
                "num_components": n_comp,
            })

    if manual_pairs:
        results_by_key = {(r["layer"], r["head"]): r for r in results}
        manual_selected = []
        missing = []
        for pair in manual_pairs:
            res = results_by_key.get(pair)
            if res:
                manual_selected.append(res)
            else:
                missing.append(pair)
        if missing:
            print(f"[analyze_heads] Warning: manual heads not found in tensor: {missing}")
        if manual_selected:
            return manual_selected

    # Filter and sort: keep heads above threshold, prefer non-bottom-row
    kept = [r for r in results if np.isfinite(r["spatial_entropy"]) and r["attn_sum"] >= thr_val and not r["bottom_row_focus"] and r["layer"] > 1]
    if len(kept) < cfg.logic.threshold.min_keep:
        # fallback: take top by sum if too few
        by_sum = sorted(results, key=lambda x: x["attn_sum"], reverse=True)
        kept = [x for x in by_sum if not x["bottom_row_focus"]][: cfg.logic.threshold.min_keep]

    kept.sort(key=lambda x: x["spatial_entropy"])  # ascending
    return kept
